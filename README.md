# DUENformer
In underwater environments, imaging devices face numerous challenges, including turbid water, light attenuation, and scattering. These factors collectively degrade the image quality, reduce contrast, and cause color distortion, posing significant challenges to underwater vision tasks. To address these issues, this study proposes a dual-branch underwater image enhancement approach that combines CNN and Transformer architectures. Firstly, a Color Correction Module (CCM) was designed to address color bias. Additionally, a Multi-level Cascade Subnetwork (MCSNet) is designed to effectively perform context modeling, enabling accurate fusion of color information and contextual information. By progressively extracting and integrating color and contextual information from the image at each level, MCSNet enhances the ability to understand complex scenes. Finally, a Frequency-domain and Spatial-domain Fusion Transformer Module (FSTM) was designed to process information in both domains, effectively supplementing detailed information. The experimental results on the UIEB, LUSI, and EUVP datasets demonstrate that the PSNR, SSIM, and MSE reach 24.44/0.91/425, 29.35/0.93/155, and 30.78/0.93/79, respectively. Compared to several state-of-the-art networks, certain improvements have been achieved. 
![Image text](https://github.com/ShanZheNaTi/DUENformer/blob/main/figures/overall.png)
## __Training__  
If you wish to train our method, you must download the UIEB dataset and create a data folder. Within this folder, two sub-folders should be created: the input folder for storing degraded images and the GT folder for storing label images.  
In addition, it is necessary to establish a checkpoint folder to save weights during training and create a sample12 folder to visualize the images generated throughout the training process.  
__Environmental requirements:__  
einops == 0.7.0；scikit-image == 0.21.0；tensorboardX == 2.6.2.2；timm == 0.9.12；torch == 1.11.0+cu113；python == 3.8.10  
## __Testing__ 
If you wish to test this method, you must create a test folder. Within this folder, two sub-files must be created: one for the input folder and the other for the GT folder. The input folder will store the degraded image used for testing, while the GT folder will store the label image used for testing.
